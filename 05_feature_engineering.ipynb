{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86746616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Advanced Feature Engineering & Optimization\n",
      "Current Best: SVM with 0.7362 Macro-F1\n",
      "Target: 0.80+ Macro-F1\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import load_npz, save_npz, hstack\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"Step 5: Advanced Feature Engineering & Optimization\")\n",
    "print(\"Current Best: SVM with 0.7362 Macro-F1\")\n",
    "print(\"Target: 0.80+ Macro-F1\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f189f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9616, Val: 1698, Test: 7532\n"
     ]
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, \n",
    "                                       remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, \n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X_train_full = newsgroups_train.data\n",
    "y_train_full = newsgroups_train.target\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.15, stratify=y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8987a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced cleaning applied\n",
      "Sample: y all lighten up on harry skip ll be like that in a couple of years harry s a great personality he s the reason i like cubs broadcasts it s certainly not the quality of the team chop chop michael mule\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "additional_stopwords = {'ax', 'max', 'article', 'writes', 'posting', 'post', 'subject', 'lines', 'organization'}\n",
    "stop_words = list(ENGLISH_STOP_WORDS.union(additional_stopwords))\n",
    "\n",
    "def clean_text_advanced(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "X_train_clean_adv = [clean_text_advanced(doc) for doc in X_train]\n",
    "X_val_clean_adv = [clean_text_advanced(doc) for doc in X_val]\n",
    "X_test_clean_adv = [clean_text_advanced(doc) for doc in X_test]\n",
    "\n",
    "print(\"Advanced cleaning applied\")\n",
    "print(f\"Sample: {X_train_clean_adv[0][:200]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b394ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 1 - Optimized Word TF-IDF:\n",
      "  Features: 50,000\n",
      "  Sparsity: 99.86%\n",
      "  SVM Macro-F1: 0.7581\n",
      "  Gain over baseline: +0.0219\n"
     ]
    }
   ],
   "source": [
    "tfidf_v1 = TfidfVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=50000,\n",
    "    min_df=2,\n",
    "    max_df=0.7,\n",
    "    sublinear_tf=True,\n",
    "    stop_words=stop_words\n",
    ")\n",
    "\n",
    "X_train_v1 = tfidf_v1.fit_transform(X_train_clean_adv)\n",
    "X_val_v1 = tfidf_v1.transform(X_val_clean_adv)\n",
    "\n",
    "print(f\"\\nStrategy 1 - Optimized Word TF-IDF:\")\n",
    "print(f\"  Features: {X_train_v1.shape[1]:,}\")\n",
    "print(f\"  Sparsity: {(1.0 - X_train_v1.nnz / (X_train_v1.shape[0] * X_train_v1.shape[1]))*100:.2f}%\")\n",
    "\n",
    "svm_v1 = LinearSVC(C=1.0, max_iter=2000, dual=False, random_state=42)\n",
    "svm_v1.fit(X_train_v1, y_train)\n",
    "y_val_pred_v1 = svm_v1.predict(X_val_v1)\n",
    "f1_v1 = f1_score(y_val, y_val_pred_v1, average='macro')\n",
    "\n",
    "print(f\"  SVM Macro-F1: {f1_v1:.4f}\")\n",
    "print(f\"  Gain over baseline: {f1_v1 - 0.7362:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6571359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 2 - Enhanced Hybrid (Word+Char):\n",
      "  Features: 70,000\n",
      "  Sparsity: 97.81%\n",
      "  SVM Macro-F1: 0.7454\n",
      "  Gain over baseline: +0.0092\n"
     ]
    }
   ],
   "source": [
    "tfidf_word_v2 = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=40000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    sublinear_tf=True,\n",
    "    stop_words=stop_words,\n",
    "    analyzer='word'\n",
    ")\n",
    "\n",
    "tfidf_char_v2 = TfidfVectorizer(\n",
    "    ngram_range=(3, 6),\n",
    "    max_features=30000,\n",
    "    min_df=3,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    "    analyzer='char'\n",
    ")\n",
    "\n",
    "X_train_word_v2 = tfidf_word_v2.fit_transform(X_train_clean_adv)\n",
    "X_train_char_v2 = tfidf_char_v2.fit_transform(X_train)\n",
    "\n",
    "X_train_v2 = hstack([X_train_word_v2, X_train_char_v2])\n",
    "\n",
    "X_val_word_v2 = tfidf_word_v2.transform(X_val_clean_adv)\n",
    "X_val_char_v2 = tfidf_char_v2.transform(X_val)\n",
    "X_val_v2 = hstack([X_val_word_v2, X_val_char_v2])\n",
    "\n",
    "print(f\"\\nStrategy 2 - Enhanced Hybrid (Word+Char):\")\n",
    "print(f\"  Features: {X_train_v2.shape[1]:,}\")\n",
    "print(f\"  Sparsity: {(1.0 - X_train_v2.nnz / (X_train_v2.shape[0] * X_train_v2.shape[1]))*100:.2f}%\")\n",
    "\n",
    "svm_v2 = LinearSVC(C=1.0, max_iter=2000, dual=False, random_state=42)\n",
    "svm_v2.fit(X_train_v2, y_train)\n",
    "y_val_pred_v2 = svm_v2.predict(X_val_v2)\n",
    "f1_v2 = f1_score(y_val, y_val_pred_v2, average='macro')\n",
    "\n",
    "print(f\"  SVM Macro-F1: {f1_v2:.4f}\")\n",
    "print(f\"  Gain over baseline: {f1_v2 - 0.7362:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6211d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Strategy 3 - Aggressive Filtering (max_df=0.5):\n",
      "  Features: 21,447\n",
      "  SVM Macro-F1: 0.7406\n",
      "  Gain over baseline: +0.0044\n"
     ]
    }
   ],
   "source": [
    "tfidf_v3 = TfidfVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=30000,\n",
    "    min_df=5,\n",
    "    max_df=0.5,\n",
    "    sublinear_tf=True,\n",
    "    stop_words=stop_words\n",
    ")\n",
    "\n",
    "X_train_v3 = tfidf_v3.fit_transform(X_train_clean_adv)\n",
    "X_val_v3 = tfidf_v3.transform(X_val_clean_adv)\n",
    "\n",
    "print(f\"\\nStrategy 3 - Aggressive Filtering (max_df=0.5):\")\n",
    "print(f\"  Features: {X_train_v3.shape[1]:,}\")\n",
    "\n",
    "svm_v3 = LinearSVC(C=1.0, max_iter=2000, dual=False, random_state=42)\n",
    "svm_v3.fit(X_train_v3, y_train)\n",
    "y_val_pred_v3 = svm_v3.predict(X_val_v3)\n",
    "f1_v3 = f1_score(y_val, y_val_pred_v3, average='macro')\n",
    "\n",
    "print(f\"  SVM Macro-F1: {f1_v3:.4f}\")\n",
    "print(f\"  Gain over baseline: {f1_v3 - 0.7362:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcad7d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Feature Strategy: v1 with F1=0.7581\n",
      "\n",
      "Starting Grid Search on SVM hyperparameters...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Grid Search Complete (9.5s)\n",
      "Best params: {'C': 1.0, 'max_iter': 2000}\n",
      "Best CV score: 0.7455\n",
      "Validation Macro-F1: 0.7581\n",
      "Gain over baseline: +0.0219\n"
     ]
    }
   ],
   "source": [
    "best_strategy = max([(f1_v1, 'v1', X_train_v1, X_val_v1), \n",
    "                      (f1_v2, 'v2', X_train_v2, X_val_v2),\n",
    "                      (f1_v3, 'v3', X_train_v3, X_val_v3)], key=lambda x: x[0])\n",
    "\n",
    "best_f1, best_name, X_train_best, X_val_best = best_strategy\n",
    "\n",
    "print(f\"\\nBest Feature Strategy: {best_name} with F1={best_f1:.4f}\")\n",
    "print(\"\\nStarting Grid Search on SVM hyperparameters...\")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "    'max_iter': [2000]\n",
    "}\n",
    "\n",
    "svm_grid = LinearSVC(dual=False, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    svm_grid,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "grid_search.fit(X_train_best, y_train)\n",
    "grid_time = time.time() - start\n",
    "\n",
    "print(f\"\\nGrid Search Complete ({grid_time:.1f}s)\")\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_val_pred_best = best_svm.predict(X_val_best)\n",
    "f1_tuned = f1_score(y_val, y_val_pred_best, average='macro')\n",
    "\n",
    "print(f\"Validation Macro-F1: {f1_tuned:.4f}\")\n",
    "print(f\"Gain over baseline: {f1_tuned - 0.7362:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704d4c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Logistic Regression with optimal features...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "\n",
      "Best params: {'C': 10.0, 'multi_class': 'multinomial', 'solver': 'lbfgs'}\n",
      "Best CV score: 0.7396\n",
      "Validation Macro-F1: 0.7481\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting Logistic Regression with optimal features...\")\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.5, 1.0, 2.0, 5.0, 10.0],\n",
    "    'solver': ['lbfgs'],\n",
    "    'multi_class': ['multinomial']\n",
    "}\n",
    "\n",
    "lr_grid = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "grid_search_lr = GridSearchCV(\n",
    "    lr_grid,\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lr.fit(X_train_best, y_train)\n",
    "\n",
    "print(f\"\\nBest params: {grid_search_lr.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search_lr.best_score_:.4f}\")\n",
    "\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "y_val_pred_lr = best_lr.predict(X_val_best)\n",
    "f1_lr_tuned = f1_score(y_val, y_val_pred_lr, average='macro')\n",
    "\n",
    "print(f\"Validation Macro-F1: {f1_lr_tuned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d95cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building Voting Ensemble...\n",
      "Ensemble Voting Macro-F1: 0.7567\n",
      "Gain over best single model: -0.0014\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding Voting Ensemble...\")\n",
    "\n",
    "ensemble_voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', best_svm),\n",
    "        ('lr', best_lr),\n",
    "        ('nb', MultinomialNB(alpha=0.1))\n",
    "    ],\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ensemble_voting.fit(X_train_best, y_train)\n",
    "y_val_pred_ensemble = ensemble_voting.predict(X_val_best)\n",
    "f1_ensemble = f1_score(y_val, y_val_pred_ensemble, average='macro')\n",
    "\n",
    "print(f\"Ensemble Voting Macro-F1: {f1_ensemble:.4f}\")\n",
    "print(f\"Gain over best single model: {f1_ensemble - max(f1_tuned, f1_lr_tuned):+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e70be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 5 RESULTS: Feature Engineering & Optimization\n",
      "================================================================================\n",
      "                         Approach  Macro_F1   Gain\n",
      "Strategy 1: Word(1-3) + stopwords    0.7581 0.0219\n",
      "            Best + SVM GridSearch    0.7581 0.0219\n",
      "                  Voting Ensemble    0.7567 0.0205\n",
      "         Best + LogReg GridSearch    0.7481 0.0119\n",
      "   Strategy 2: Word+Char Enhanced    0.7454 0.0092\n",
      "    Strategy 3: Aggressive Filter    0.7406 0.0044\n",
      "                Baseline (Step 4)    0.7362 0.0000\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "results_step5 = pd.DataFrame({\n",
    "    'Approach': [\n",
    "        'Baseline (Step 4)',\n",
    "        'Strategy 1: Word(1-3) + stopwords',\n",
    "        'Strategy 2: Word+Char Enhanced',\n",
    "        'Strategy 3: Aggressive Filter',\n",
    "        'Best + SVM GridSearch',\n",
    "        'Best + LogReg GridSearch',\n",
    "        'Voting Ensemble'\n",
    "    ],\n",
    "    'Macro_F1': [\n",
    "        0.7362,\n",
    "        f1_v1,\n",
    "        f1_v2,\n",
    "        f1_v3,\n",
    "        f1_tuned,\n",
    "        f1_lr_tuned,\n",
    "        f1_ensemble\n",
    "    ],\n",
    "    'Gain': [\n",
    "        0,\n",
    "        f1_v1 - 0.7362,\n",
    "        f1_v2 - 0.7362,\n",
    "        f1_v3 - 0.7362,\n",
    "        f1_tuned - 0.7362,\n",
    "        f1_lr_tuned - 0.7362,\n",
    "        f1_ensemble - 0.7362\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_step5 = results_step5.sort_values('Macro_F1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5 RESULTS: Feature Engineering & Optimization\")\n",
    "print(\"=\"*80)\n",
    "print(results_step5.round(4).to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_approach = results_step5.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5568347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Saved: models/best_step5_lr.pkl\n",
      "ðŸ’¾ Saved vectorizers\n"
     ]
    }
   ],
   "source": [
    "if best_approach['Approach'] == 'Voting Ensemble':\n",
    "    joblib.dump(ensemble_voting, 'models/best_step5_ensemble.pkl')\n",
    "    final_model = ensemble_voting\n",
    "    print(\"\\nðŸ’¾ Saved: models/best_step5_ensemble.pkl\")\n",
    "elif 'SVM' in best_approach['Approach']:\n",
    "    joblib.dump(best_svm, 'models/best_step5_svm.pkl')\n",
    "    final_model = best_svm\n",
    "    print(\"\\nðŸ’¾ Saved: models/best_step5_svm.pkl\")\n",
    "else:\n",
    "    joblib.dump(best_lr, 'models/best_step5_lr.pkl')\n",
    "    final_model = best_lr\n",
    "    print(\"\\nðŸ’¾ Saved: models/best_step5_lr.pkl\")\n",
    "\n",
    "if best_name == 'v1':\n",
    "    joblib.dump(tfidf_v1, 'models/tfidf_best_step5.pkl')\n",
    "elif best_name == 'v2':\n",
    "    joblib.dump(tfidf_word_v2, 'models/tfidf_word_best_step5.pkl')\n",
    "    joblib.dump(tfidf_char_v2, 'models/tfidf_char_best_step5.pkl')\n",
    "else:\n",
    "    joblib.dump(tfidf_v3, 'models/tfidf_best_step5.pkl')\n",
    "\n",
    "print(\"ðŸ’¾ Saved vectorizers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11f396c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLASSIFICATION REPORT - Strategy 1: Word(1-3) + stopwords\n",
      "================================================================================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism     0.7000    0.5833    0.6364        72\n",
      "           comp.graphics     0.7128    0.7614    0.7363        88\n",
      " comp.os.ms-windows.misc     0.7011    0.6854    0.6932        89\n",
      "comp.sys.ibm.pc.hardware     0.6250    0.6818    0.6522        88\n",
      "   comp.sys.mac.hardware     0.7901    0.7356    0.7619        87\n",
      "          comp.windows.x     0.8171    0.7528    0.7836        89\n",
      "            misc.forsale     0.7805    0.7273    0.7529        88\n",
      "               rec.autos     0.4931    0.7978    0.6094        89\n",
      "         rec.motorcycles     0.8462    0.7333    0.7857        90\n",
      "      rec.sport.baseball     0.7938    0.8652    0.8280        89\n",
      "        rec.sport.hockey     0.9512    0.8667    0.9070        90\n",
      "               sci.crypt     0.8831    0.7640    0.8193        89\n",
      "         sci.electronics     0.7228    0.8202    0.7684        89\n",
      "                 sci.med     0.8478    0.8764    0.8619        89\n",
      "               sci.space     0.8148    0.7416    0.7765        89\n",
      "  soc.religion.christian     0.7157    0.8111    0.7604        90\n",
      "      talk.politics.guns     0.7805    0.7805    0.7805        82\n",
      "   talk.politics.mideast     0.8554    0.8353    0.8452        85\n",
      "      talk.politics.misc     0.7424    0.7000    0.7206        70\n",
      "      talk.religion.misc     0.6774    0.3750    0.4828        56\n",
      "\n",
      "                accuracy                         0.7538      1698\n",
      "               macro avg     0.7625    0.7447    0.7481      1698\n",
      "            weighted avg     0.7650    0.7538    0.7545      1698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_names = newsgroups_train.target_names\n",
    "\n",
    "if best_approach['Approach'] == 'Voting Ensemble':\n",
    "    y_val_final = y_val_pred_ensemble\n",
    "elif 'SVM' in best_approach['Approach']:\n",
    "    y_val_final = y_val_pred_best\n",
    "else:\n",
    "    y_val_final = y_val_pred_lr\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"CLASSIFICATION REPORT - {best_approach['Approach']}\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_val, y_val_final, target_names=category_names, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
